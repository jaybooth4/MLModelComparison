{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert our own Handwriting into compatible datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy import ndimage\n",
    "import math\n",
    "import cv2\n",
    "import os\n",
    "#For Debugging\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "# create an array where we can store our 12 characters\n",
    "images = np.zeros((12,784))\n",
    "# and the labels\n",
    "correct_vals = np.zeros((12,46))\n",
    "\n",
    "# WE WANT ML 2018 using the labels specified in 'EMNIST Import and Application by SKLearn'\n",
    "i = 0\n",
    "labels = [14,32,21,24,31,32,22,21,2,0,1,8]\n",
    "\n",
    "for letter in [\"W\",\"E1\",\"L1\",\"O\",\"V\",\"E2\",\"M\",\"L2\",\"2\",\"0\",\"1\",\"8\"]:\n",
    "    # read the image\n",
    "    gray = cv2.imread(letter+\"booth.png\", 0)\n",
    "    #invert the image, convert to grayscale using the threshold of 50 / 225 to decide whether or not it is actually a pencil mark\n",
    "    _, gray = cv2.threshold(255-gray, 50, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    #gray = cv2.resize(gray,(28, 28))\n",
    "\n",
    "    \n",
    "    #Remove any lines of all black\n",
    "    while np.sum(gray[0]) == 0:\n",
    "        gray = gray[1:]\n",
    "\n",
    "    while np.sum(gray[:,0]) == 0:\n",
    "        gray = np.delete(gray,0,1)\n",
    "\n",
    "    while np.sum(gray[-1]) == 0:\n",
    "        gray = gray[:-1]\n",
    "\n",
    "    while np.sum(gray[:,-1]) == 0:\n",
    "        gray = np.delete(gray,-1,1)\n",
    "    \n",
    "    rows,cols = gray.shape\n",
    "    \n",
    "    #gray = np.lib.pad(gray,(rowsPadding,colsPadding),'constant') \n",
    "    #Calculate how uch buffer is needed to add to the image to make it square again\n",
    "    if rows > cols:\n",
    "        factor = 20.0/rows\n",
    "        rows = 20\n",
    "        cols = int(round(cols*factor))\n",
    "        gray = cv2.resize(gray, (cols,rows))\n",
    "    else:\n",
    "        factor = 20.0/cols\n",
    "        cols = 20\n",
    "        rows = int(round(rows*factor))\n",
    "        gray = cv2.resize(gray, (cols, rows))\n",
    "    colsPadding = (int(math.ceil((28-cols)/2.0)),int(math.floor((28-cols)/2.0)))\n",
    "    rowsPadding = (int(math.ceil((28-rows)/2.0)),int(math.floor((28-rows)/2.0)))\n",
    "    #Center the image\n",
    "    cy,cx = ndimage.measurements.center_of_mass(gray)\n",
    "    rows,cols = gray.shape\n",
    "    shiftx = np.round(cols/2.0-cx).astype(int)\n",
    "    shifty = np.round(rows/2.0-cy).astype(int)\n",
    "    #Add the padding to make the image square again\n",
    "    gray = np.lib.pad(gray,(rowsPadding,colsPadding),'constant')\n",
    "    gray = cv2.resize(gray,(28, 28))\n",
    "    #The current images have a range of 0-255 and we want to convert it to between 0-1\n",
    "    flatten = gray.flatten() / 255.0\n",
    "    #Write the images\n",
    "    cv2.imwrite(letter+\"boothPRO.png\", gray)\n",
    "    #print (gray)\n",
    "    #print (flatten)\n",
    "    #print(len(images[i]))\n",
    "    #print(len(flatten))\n",
    "    #Keep track of the data for each image as well as the correct labels \n",
    "    images[i] = flatten\n",
    "    correct_val = np.zeros((46))\n",
    "    correct_val[labels[i]] = 1\n",
    "    correct_vals[i] = correct_val\n",
    "    i += 1\n",
    "\n",
    "#print (images)\n",
    "#Save the binary images\n",
    "np.save(\"binaryLetters.npy\",images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
